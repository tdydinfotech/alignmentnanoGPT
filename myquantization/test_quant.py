import torch

import torch


def quantize_per_tensor(tensor, scale, zero_point, dtype):
    # å°†è¾“å…¥å¼ é‡æŒ‰ç…§ç¼©æ”¾å› å­å’Œé›¶ç‚¹å› å­è¿›è¡Œé‡åŒ–
    # å…¬å¼ï¼šğ’™ğ’’ = ğ‘…(ğ’™/ğ‘†) âˆ’ ğ‘
    quantized_tensor = torch.round(tensor / scale) - zero_point

    # é™åˆ¶é‡åŒ–åçš„å¼ é‡å€¼åœ¨åˆæ³•èŒƒå›´å†…
    quantized_tensor = torch.clamp(quantized_tensor, torch.iinfo(dtype).min, torch.iinfo(dtype).max)

    # è½¬æ¢ä¸ºæŒ‡å®šçš„æ•°æ®ç±»å‹
    # æ˜¾ç¤ºæŒ‡å®šé‡åŒ–åçš„æ•°æ®ç±»å‹
    # quantized_tensor = quantized_tensor.to(torch.float)  # å°†é‡åŒ–åçš„å¼ é‡è½¬æ¢ä¸ºæµ®ç‚¹å‹
    quantized_tensor = quantized_tensor.contiguous()
    quantized_tensor = quantized_tensor.to(dtype)  # å†è½¬æ¢ä¸ºæŒ‡å®šçš„æ•°æ®ç±»å‹

    return quantized_tensor
if __name__ == '__main__':
    # ç¤ºä¾‹ç”¨æ³•
    model_weight = torch.randn(2, 2)

    scale = torch.tensor(0.05)  # ç¼©æ”¾å› å­
    zero_point = torch.tensor(0)  # é›¶ç‚¹å› å­
    quantized_weight = quantize_per_tensor(model_weight, scale, zero_point, torch.qint8)
    print(quantized_weight)


# # å‡è®¾ model æ˜¯ä¸€ä¸ªå·²ç»å®šä¹‰å¥½çš„ nn.Linear å±‚
# model = torch.nn.Linear(10, 20)
#
# # æ”¶é›†æƒé‡çš„ç»Ÿè®¡ä¿¡æ¯
# min_val, max_val = torch.min(model.weight), torch.max(model.weight)
#
# # è®¡ç®—é‡åŒ–å°ºåº¦å’Œé›¶ç‚¹
# scale = max(abs(min_val), abs(max_val)) / 127.0
# zero_point = torch.tensor(0, dtype=torch.int32)
#
# # é‡åŒ–æƒé‡
# quantized_weight = quantize_per_tensor(model.weight, scale, zero_point, torch.qint8)
#
# # å°†é‡åŒ–åçš„æƒé‡èµ‹å€¼å›æ¨¡å‹çš„æƒé‡
# model.weight.data = quantized_weight